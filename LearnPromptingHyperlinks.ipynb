{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415f48f-63dc-47d9-b487-588138e284bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\Users\\cpola\\Learn_Prompting_nextjs\\app\\(docs)\\docs\\agents\\introduction\\page.mdx\n",
      "Processing: C:\\Users\\cpola\\Learn_Prompting_nextjs\\app\\(docs)\\docs\\agents\\mrkl\\page.mdx\n",
      "Processing: C:\\Users\\cpola\\Learn_Prompting_nextjs\\app\\(docs)\\docs\\agents\\pal\\page.mdx\n",
      "Processing: C:\\Users\\cpola\\Learn_Prompting_nextjs\\app\\(docs)\\docs\\agents\\react\\page.mdx\n",
      "\n",
      "Processing complete!\n",
      "Total files processed: 4\n",
      "Files modified: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Removed API key \n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, docs_path: str, backup_path: str):\n",
    "        self.docs_path = Path(docs_path)\n",
    "        self.backup_path = Path(backup_path)\n",
    "        self.article_titles = {}  \n",
    "        \n",
    "    def get_mdx(self):\n",
    "        \"\"\"Returns list of all .mdx files in the docs directory\"\"\"\n",
    "        return list(self.docs_path.rglob(\"*.mdx\"))\n",
    "    \n",
    "    def find_titles(self):\n",
    "        \"\"\"Maps article headings to their paths\"\"\"\n",
    "        mdx_files = self.get_mdx()\n",
    "        \n",
    "        for file_path in mdx_files:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            \n",
    "            heading_line = [line for line in content.split('\\n') if 'heading:' in line]\n",
    "            if heading_line:\n",
    "                heading = heading_line[0].split('heading:')[1].strip().strip('\"').lstrip('◆').strip()\n",
    "                relative_path = str(file_path.parent.relative_to(self.docs_path))\n",
    "                hyperlink_path = f\"/{relative_path.replace(os.sep, '/')}\"\n",
    "                self.article_titles[heading] = hyperlink_path\n",
    "            \n",
    "    def process_article(self, file_path: Path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        heading_line = [line for line in content.split('\\n') if 'heading:' in line]\n",
    "        current_heading = heading_line[0].split('heading:')[1].strip().strip('\"').lstrip('◆').strip() if heading_line else \"\"\n",
    "        \n",
    "        filtered_titles = {\n",
    "            title: path \n",
    "            for title, path in self.article_titles.items() \n",
    "            if title != current_heading\n",
    "        }\n",
    "        \n",
    "        updated_content = self.call_chat(\n",
    "            content=content,\n",
    "            titles=filtered_titles,\n",
    "            current_folder=str(file_path.parent)\n",
    "        )\n",
    "        \n",
    "        if content != updated_content:\n",
    "            self.save_results(file_path, content, updated_content)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def call_chat(self, content: str, titles: dict, current_folder: str) -> str:\n",
    "        title_list = \"\\n\".join([f\"- {title}: {path}\" for title, path in titles.items()])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Markdown editor. Here is a list of article titles and their paths:\n",
    "        {title_list}\n",
    "\n",
    "        Identify where these titles appear in the following Markdown content and \n",
    "        insert hyperlinks pointing to the corresponding paths. Return the updated content.\n",
    "\n",
    "        Content:\n",
    "        {content}\n",
    "\n",
    "        Rules:\n",
    "        1. **You cannot delete anything**, not even whitespace or extra lines.\n",
    "        2. Do not modify existing hyperlinks [text](path)\n",
    "        3. Do not modify or delete 'metadata.heading' anywhere\n",
    "        4. Do not hyperlink 'introduction' \n",
    "        5. Matching should be case-insensitive\n",
    "        6. Only hyperlink the first instance of each term\n",
    "        7. Only hyperlink standalone terms (with spaces on both sides)\n",
    "        8. Do not add or replace any '`' and do not write 'Markdown' anywhere\n",
    "        9. Do not delete any citations that appear after terms, for example 'term (@citation)'\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert Markdown content editor. Return only the raw content without any markdown formatting markers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        updated_content = response['choices'][0]['message']['content']\n",
    "        \n",
    "       \n",
    "        updated_content = updated_content.strip('`').strip()\n",
    "        if updated_content.startswith('markdown\\n'):\n",
    "            updated_content = updated_content[9:]\n",
    "            \n",
    "        return updated_content\n",
    "    \n",
    "    def save_results(self, file_path: Path, original: str, updated: str):\n",
    "        self.backup_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        backup_file = self.backup_path / file_path.name\n",
    "        with open(backup_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(original)\n",
    "            \n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(updated)\n",
    "            \n",
    "        with open(self.backup_path / \"change_log.txt\", \"a\", encoding='utf-8') as log:\n",
    "            log.write(f\"Updated and backed up: {file_path}\\n\")\n",
    "            \n",
    "    def process_all_documents(self):\n",
    "        \"\"\"Main processing function\"\"\"\n",
    "        self.find_titles()\n",
    "        \n",
    "        processed_count = 0\n",
    "        modified_count = 0\n",
    "        \n",
    "        for file_path in self.get_mdx():\n",
    "            print(f\"Processing: {file_path}\")\n",
    "            processed_count += 1\n",
    "            if self.process_article(file_path): \n",
    "                modified_count += 1\n",
    "                \n",
    "        print(f\"\\nProcessing complete!\")\n",
    "        print(f\"Total files processed: {processed_count}\")\n",
    "        print(f\"Files modified: {modified_count}\")\n",
    "\n",
    "def main():\n",
    "    docs_path = r\"\" # removed for privacy\n",
    "    backup_path = r\"\" # removed for privacy\n",
    "    \n",
    "    processor = DocumentProcessor(docs_path, backup_path)\n",
    "    processor.process_all_documents()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c4917-11bf-4335-8147-5a81587df47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
